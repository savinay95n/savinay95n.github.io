<html><head>
    <title>TSMU</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">


</head>

<body>
    <br><br><br><br>
    <div class="container">
        <div class="row text-center" style="font-size:38px">
            <div class="col">
                Comparison of reinforcement learning algorithms applied to the cart-pole problem
            </div>
        </div>

        <br>
        <div class="row text-center" style="font-size:28px">
            <div class="col">
                ICACCI 2017
            </div>
        </div>
        <br>

        <div class="h-100 row text-center heavy justify-content-md-center" style="font-size:28px;">
            <div class="col-sm-auto px-lg-4">
                <a href="">Savinay Nagendra</a>
            </div>
            <div class="col-sm-auto px-lg-4">
                <nobr><a href="https://www.linkedin.com/in/nikhil-podila/?originalSubdomain=ca">Nikhil Podila</a></nobr>
            </div>
            <div class="col-sm-auto px-lg-4">
                <nobr><a href="https://www.linkedin.com/in/koshy-george-175644249/?originalSubdomain=in">Koshy George</a></nobr>
            </div>
            <br>
            <br>
            <br>
            <div class="row text-center" style="font-size:28px">
                <div class="col">
                    Abstract
                </div>
            </div>
            <br>
            
            <p style="text-align: justify;">
                Designing optimal controllers continues to be challenging as systems are becoming complex and are inherently nonlinear. The principal advantage of reinforcement learning (RL) is its ability to learn from the interaction with the environment and provide optimal control strategy. In this paper, RL is explored in the context of control of the benchmark cart-pole dynamical system with no prior knowledge of the dynamics. RL algorithms such as temporal-difference, policy gradient actor-critic, and value function approximation are compared in this context with the standard LQR solution. Further, we propose a novel approach to integrate RL and swing-up controllers.  
            </p>
            <br>
            <br>

            <div class="col-sm-auto px-lg-4">
                <a href="https://ieeexplore.ieee.org/abstract/document/8125811">[arXiv]</a>
            </div>
            <div class="col-sm-auto px-lg-4">
                <a href="https://arxiv.org/ftp/arxiv/papers/1810/1810.01940.pdf">[Paper]</a>
            </div>
            <div class="col-sm-auto px-lg-4">
                <a href="https://github.com/savinay95n/Reinforcement-learning-Algorithms-and-Dynamic-Programming">[Code]</a>
            </div>

            <br>
            <br>
            
            <div class="row text-center">
                <div class="col">
                    <img width="100%" src="cart2.png">
                    <br>
                    <br>
                    <img width="100%" src="cart3.png">
                </div>
            </div>

            <br>
            <br>
            <br>
            <br>
            <hr>
            <div class="row text-center" style="font-size:28px">
                <div class="col">
                    Citation
                </div>
            </div>
            <br>

            <div class="row">
                <div class="col s12 l10 push-l1 xl8 push-xl2">
                  <pre style="background-color: aliceblue;overflow:auto;padding: 10px; text-align: left;">@inproceedings{nagendra2017comparison,
                    title={Comparison of reinforcement learning algorithms applied to the cart-pole problem},
                    author={Nagendra, Savinay and Podila, Nikhil and Ugarakhod, Rashmi and George, Koshy},
                    booktitle={2017 international conference on advances in computing, communications and informatics (ICACCI)},
                    pages={26--32},
                    year={2017},
                    organization={IEEE}
                  }</pre>
                </div>
              </div>
            
            

        </div>
        </div>
        </body>
        </html>
    



